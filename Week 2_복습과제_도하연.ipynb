{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2befca-37c8-4a9a-bb1c-946cfc1ae32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df = pd.read_csv('/Users/Doh/#University/Club/Euron/titanic_train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc82d90-d661-4115-bd98-58823586a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n ###학습 데이터 정보### \\n')\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6c54c6-fe3b-476d-8d2a-8b047698d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "titanic_df['Embarked'].fillna('N', inplace=True)\n",
    "print('데이터세트 Null값 개수', titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803c9c7-4065-43f2-9daa-a3f0a40264cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Sex 값 분포: \\n', titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin값 분포:\\n', titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked값 분포:\\n', titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cd7cd-74ff-4868-9e2f-d58e160a8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df['Cabin']=titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df['Cabin'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704ac93-9696-47d4-91dc-56bbfbc86d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c9773-cad3-4af6-a0a6-f17699afa4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Sex', y='Survived', data = titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47cc11-caee-4f66-ade9-f61b3e6999ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8e34c-dd1d-4a3d-b87e-a99dc5f23911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 age에 따라 구분 값을 반환하는 함수 설정. DataFrame의 apply lambda 식에 사용.\n",
    "def get_category(age):\n",
    "  cat = ''\n",
    "  if age <= -1: cat = 'Unknown'\n",
    "  elif age <= 5: cat = 'Baby'\n",
    "  elif age <= 12: cat = 'Child'\n",
    "  elif age <= 18: cat = 'Teenager'\n",
    "  elif age <= 25: cat = 'Student'\n",
    "  elif age <= 35: cat = 'Young Adult'\n",
    "  elif age <= 60: cat = 'Adult'\n",
    "  else: cat = 'Elderly'\n",
    "\n",
    "  return cat\n",
    "\n",
    "#막대그래프의 크기 figure를 더 크게 설정\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "#x축 값을 순차적으로 표시하기 위한 설정\n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']\n",
    "\n",
    "#lambda 식에 위에서 생성한 get_category()함수를 반환값으로 지정.\n",
    "#get_category(X)는 입력값으로 'Age' 칼럼값을 받아서 해당하는 cat 반환\n",
    "# 원본데이터를 보존시키기 위해 삽입했던 Age_cat 열 삭제\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)\n",
    "titanic_df.drop('Age_cat', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2a288-e7e0-4bf6-9f6d-0e9fe18edee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_features(dataDF):\n",
    "  features = ['Cabin', 'Sex', 'Embarked']\n",
    "  for feature in features:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(dataDF[feature])\n",
    "    dataDF[feature] = le.transform(dataDF[feature])\n",
    "\n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463a2c0-9d79-4ff4-83ae-8fcb16dd3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null 처리 함수\n",
    "def fillna(df):\n",
    "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "  df['Cabin'].fillna('N',inplace=True)\n",
    "  df['Embarked'].fillna('N',inplace=True)\n",
    "  df['Fare'].fillna(0,inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "  df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "  return df\n",
    "\n",
    "# 레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "      le = LabelEncoder()\n",
    "      le = le.fit(df[feature])\n",
    "      df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "#앞에서 설정한 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "  df = fillna(df)\n",
    "  df = drop_features(df)\n",
    "  df = format_features(df)\n",
    "  return df\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aad135-b6fe-44e0-a5b4-8344ae869349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터를 재로딩하고 피처 데이터 세트와 레이블 데이터 세트 추출\n",
    "titanic_df = pd.read_csv('/Users/Doh/#University/Club/Euron/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b89b414-bf0b-4496-a6f7-1dff928e1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d7c27-5332-46fc-bc47-4c79dc5ce47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#결정트리, RandomForest, 로지스틱 회귀 위한 사이킷런 Classifier 클래스 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "#DecisionTreeClassifier 학습 / 예측 / 평가\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print(accuracy_score(y_test,dt_pred))\n",
    "\n",
    "#RandomForestClassifier 학습 / 예측 / 평가\n",
    "rf_clf.fit(X_train,y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print(accuracy_score(y_test,rf_pred))\n",
    "\n",
    "#LogisticRegression 학습 / 예측 / 평가\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print(accuracy_score(y_test,lr_pred))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb111a3-b764-4e6a-9a51-8af655e6a561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 검증\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트 5개인 KFold 생성,\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "\n",
    "    # KFold 교차 검증 수행\n",
    "    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # x_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        # Classifier 학습, 예측, 정확도 계산\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도 : {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "    # 5개의 fold 에서 평균 정확도 계산\n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도 : {0:.4f}\".format(mean_score))\n",
    "exec_kfold(dt_clf, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5a3de-db1c-4844-bcdb-f9199bf8a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf,X_titanic_df,y_titanic_df,cv=5)\n",
    "for iter_count , accuracy in enumerate(scores):\n",
    "    print(\"교차검증 {} 정확도 : {:.4f}\".format(iter_count,accuracy))\n",
    "\n",
    "print(\"평균 정확도 : {:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66769a79-7d69-433a-858a-e401cc7e3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "\n",
    "    # KFold 교차 검증 수행.\n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "\n",
    "        # Classifier 학습, 예측, 정확도 계산\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "    # 5개 fold에서의 평균 정확도 계산\n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score))\n",
    "# exec_kfold 호출\n",
    "exec_kfold(dt_clf , folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2914733c-7e2e-4299-b886-46a7bd5b954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "  print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f1d75-15d3-4709-8bf3-c5ad4b0406bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':[2,3,5,10],'min_samples_split':[2,3,5],'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf,param_grid = parameters,scoring='accuracy',cv=5)\n",
    "grid_dclf.fit(X_train,y_train)\n",
    "\n",
    "print(\"GridSearchCV 최적 하이퍼 파라미터 :\",grid_dclf.best_params_)\n",
    "print(\"GridSearchCV 최고 정확도 :\",grid_dclf.best_score_)\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,dpredictions)\n",
    "print(\"테스트 세트에서의 DecisionTreeClassifier 정확도:{:0.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd9d0b-02bc-423a-86bf-066f1a4a3ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "diabetes_data = pd.read_csv('/Users/Doh/#University/Club/Euron/diabetes.csv')\n",
    "print(diabetes_data['Outcome'].value_counts())\n",
    "diabetes_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad7beed-1077-4bde-9666-fd1bd445321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ef1a5-5623-49d7-94ee-a43cbefd5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4322e3-4968-4708-9d45-d1ff2cdddbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 데이터 세트 X, 레이블 데이터 세트 y를 추출\n",
    "# 맨 끝이 Outcome 칼럼으로 레이블 값임. 칼럼 위치 -1을 이용해 추출\n",
    "X = diabetes_data.iloc[:, :-1]\n",
    "y = diabetes_data.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 156, stratify=y)\n",
    "\n",
    "# 로지스틱 회귀로 학습, 예측 및 평가 수행\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca83328-ae6c-4e59-b186-8588b1ef5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "  # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출\n",
    "  precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
    "\n",
    "  # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  threshold_boundary = thresholds.shape[0]\n",
    "  plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "  plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
    "\n",
    "  # threshold 값 X축의 Scale을 0.1 단위로 변경\n",
    "  start, end = plt.xlim()\n",
    "  plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "\n",
    "  # x축, y축 label과 legend, 그리고 grid 설정\n",
    "  plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "  plt.legend(); plt.grid()\n",
    "  plt.show()\n",
    "\n",
    "    \n",
    "pred_proba_c1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "precision_recall_curve_plot(y_test, pred_proba_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77215270-54a4-4173-bf9c-f3a7e05f0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927fc637-63de-44f7-abbc-a2969bcb505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diabetes_data['Glucose'], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18eff8-d70c-45a7-b7a5-942523aebdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0값을 검사할 피처명 리스트\n",
    "zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "# 전체 데이터 건수\n",
    "total_count = diabetes_data['Glucose'].count()\n",
    "\n",
    "# 피처별로 반복하면서 데이터 값이 0인 데이터 건수를 추출하고 ,퍼센트 계산\n",
    "for feature in zero_features:\n",
    "  zero_count = diabetes_data[diabetes_data[feature] == 0][feature].count()\n",
    "  print('{0} 0 건수는 {1}, 퍼센트는 {2:.2f} %'.format(feature, zero_count, 100*zero_count/total_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe850d-db0a-4d19-b2a5-a002b56cb452",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_zero_features = diabetes_data[zero_features].mean()\n",
    "diabetes_data[zero_features]=diabetes_data[zero_features].replace(0, mean_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28f9f9-f7fd-47f5-a45b-4c966821f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_data.iloc[:, :-1]\n",
    "y = diabetes_data.iloc[:, -1]\n",
    "\n",
    "# StandardScaler 클래스를 이용해 피처 데이터 세트에 일괄적으로 스케일링 적용\n",
    "scaler = StandardScaler( )\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 156, stratify=y)\n",
    "\n",
    "# 로지스틱 회귀로 학습, 예측 및 평가 수행\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train , y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test , pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38968614-33ba-472e-889d-505f0b2baf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "def get_eval_by_threshold(y_test , pred_proba_c1, thresholds):\n",
    "    # thresholds 리스트 객체내의 값을 차례로 iteration하면서 Evaluation 수행.\n",
    "    for custom_threshold in thresholds:\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임곗값:',custom_threshold)\n",
    "        get_clf_eval(y_test , custom_predict, pred_proba_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3906527-3de0-48a1-8a4a-faae3726e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3 , 0.33 ,0.36,0.39, 0.42 , 0.45 ,0.48, 0.50]\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e8043-0dfe-452c-8e15-9a740c54ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임곗값를 0.48로 설정한 Binarizer 생성\n",
    "binarizer = Binarizer(threshold=0.48)\n",
    "\n",
    "# 위에서 구한 lr_clf의 predict_proba() 예측 확률 array에서 1에 해당하는 컬럼값을 Binarizer변환. \n",
    "pred_th_048 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1,1)) \n",
    "\n",
    "get_clf_eval(y_test , pred_th_048, pred_proba[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17920cf3-318c-4603-bcca-8893690001ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
